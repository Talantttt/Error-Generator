{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Talantttt/Error-Generator/blob/main/notebooks/colab-github-demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pVhOfzLx9us"
      },
      "source": [
        "# Using Google Colab with GitHub\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKJ4bd5rt1wy"
      },
      "source": [
        "\n",
        "[Google Colaboratory](http://colab.research.google.com) is designed to integrate cleanly with GitHub, allowing both loading notebooks from github and saving notebooks to github."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-NVg7RjyeTk"
      },
      "source": [
        "## Loading Public Notebooks Directly from GitHub\n",
        "\n",
        "Colab can load public github notebooks directly, with no required authorization step.\n",
        "\n",
        "For example, consider the notebook at this address: https://github.com/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb.\n",
        "\n",
        "The direct colab link to this notebook is: https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb.\n",
        "\n",
        "To generate such links in one click, you can use the [Open in Colab](https://chrome.google.com/webstore/detail/open-in-colab/iogfkhleblhcpcekbiedikdehleodpjo) Chrome extension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzIRIt9d2huC"
      },
      "source": [
        "## Browsing GitHub Repositories from Colab\n",
        "\n",
        "Colab also supports special URLs that link directly to a GitHub browser for any user/organization, repository, or branch. For example:\n",
        "\n",
        "- http://colab.research.google.com/github will give you a general github browser, where you can search for any github organization or username.\n",
        "- http://colab.research.google.com/github/googlecolab/ will open the repository browser for the ``googlecolab`` organization. Replace ``googlecolab`` with any other github org or user to see their repositories.\n",
        "- http://colab.research.google.com/github/googlecolab/colabtools/ will let you browse the main branch of the ``colabtools`` repository within the ``googlecolab`` organization. Substitute any user/org and repository to see its contents.\n",
        "- http://colab.research.google.com/github/googlecolab/colabtools/blob/main will let you browse ``main`` branch of the ``colabtools`` repository within the ``googlecolab`` organization. (don't forget the ``blob`` here!) You can specify any valid branch for any valid repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmai0dD30XzL"
      },
      "source": [
        "## Loading Private Notebooks\n",
        "\n",
        "Loading a notebook from a private GitHub repository is possible, but requires an additional step to allow Colab to access your files.\n",
        "Do the following:\n",
        "\n",
        "1. Navigate to http://colab.research.google.com/github.\n",
        "2. Click the \"Include Private Repos\" checkbox.\n",
        "3. In the popup window, sign-in to your Github account and authorize Colab to read the private files.\n",
        "4. Your private repositories and notebooks will now be available via the github navigation pane."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J3NBxtZpPcK"
      },
      "source": [
        "## Saving Notebooks To GitHub or Drive\n",
        "\n",
        "Any time you open a GitHub hosted notebook in Colab, it opens a new editable view of the notebook. You can run and modify the notebook without worrying about overwriting the source.\n",
        "\n",
        "If you would like to save your changes from within Colab, you can use the File menu to save the modified notebook either to Google Drive or back to GitHub. Choose **File‚ÜíSave a copy in Drive** or **File‚ÜíSave a copy to GitHub** and follow the resulting prompts. To save a Colab notebook to GitHub requires giving Colab permission to push the commit to your repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QAWNjizy_3O"
      },
      "source": [
        "## Open In Colab Badge\n",
        "\n",
        "Anybody can open a copy of any github-hosted notebook within Colab. To make it easier to give people access to live views of GitHub-hosted notebooks,\n",
        "colab provides a [shields.io](http://shields.io/)-style badge, which appears as follows:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "\n",
        "The markdown for the above badge is the following:\n",
        "\n",
        "```markdown\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "```\n",
        "\n",
        "The HTML equivalent is:\n",
        "\n",
        "```HTML\n",
        "<a href=\"https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "```\n",
        "\n",
        "Remember to replace the notebook URL in this template with the notebook you want to link to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VQqVi-3ScBC",
        "outputId": "3da27aef-f8e0-44aa-8015-0383ce15d5c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: for i in range(10): print(i)\n",
            "Broken: for i in range(10) print(i)\n",
            "Error: –û—à–∏–±–∫–∞: –ø—Ä–æ–ø—É—â–µ–Ω —Å–∏–º–≤–æ–ª ':'\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def break_python_code(code: str) -> tuple[str, str, str]:\n",
        "   #\"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (–∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥, –∏—Å–ø–æ—Ä—á–µ–Ω–Ω—ã–π –∫–æ–¥, –æ–ø–∏—Å–∞–Ω–∏–µ –æ—à–∏–±–∫–∏)\"\"\"\n",
        "  if ':' in code:\n",
        "    broken = code.replace(':', '', 1)\n",
        "    return code, broken, \"–û—à–∏–±–∫–∞: –ø—Ä–æ–ø—É—â–µ–Ω —Å–∏–º–≤–æ–ª ':'\"\n",
        "  elif 'def ' in code:\n",
        "    broken = code.replace('def', '', 1)\n",
        "    return code, broken, \"–û—à–∏–±–∫–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ 'def'\"\n",
        "  elif 'print' in code:\n",
        "    broken = code.replace('print(', 'print', 1)\n",
        "    return code, broken,  \"–û—à–∏–±–∫–∞: –ø—Ä–æ–ø—É—â–µ–Ω—ã —Å–∫–æ–±–∫–∏ —É —Ñ—É–Ω–∫—Ü–∏–∏ print\"\n",
        "  else:\n",
        "    code, code  #\"–ù–µ —É–¥–∞–ª–æ—Å—å –≤–Ω–µ—Å—Ç–∏ –æ—à–∏–±–∫—É\"\n",
        "\n",
        "\n",
        "original, broken, error = break_python_code('for i in range(10): print(i)')\n",
        "print('Original:', original)\n",
        "print('Broken:', broken)\n",
        "print('Error:', error)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "examples = [\n",
        "    \"for i in range(10): print(i)\",\n",
        "    \"def hello():\\n print('Hello')\",\n",
        "    \"if x == 5:\\n print('ok)\",\n",
        "    \"print('Done')\",\n",
        "]\n",
        "\n",
        "dataset = []\n",
        "\n",
        "for _ in range(5000):\n",
        "  code = random.choice(examples)\n",
        "  original, broken, error = break_python_code(code)\n",
        "  if original != broken:\n",
        "    dataset.append({\n",
        "        \"input\": broken,\n",
        "        \"output\": f\"{error}. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥: {original}\"\n",
        "    })\n",
        "\n",
        "with open('synthetic_error_dataset.json', 'w', encoding = 'utf-8') as f:\n",
        "  json.dump(dataset, f, indent = 2, ensure_ascii = False)"
      ],
      "metadata": {
        "id": "VZhd82TuQvgv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –º–æ–¥–µ–ª—å\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# –ì–æ—Ç–æ–≤–∏–º –¥–∞—Ç–∞—Å–µ—Ç\n",
        "def create_dataset(path, tokenizer):\n",
        "  return TextDataset(\n",
        "      tokenizer = tokenizer,\n",
        "      file_path = path,\n",
        "      block_size = 128\n",
        "  )\n",
        "\n",
        "with open(\"train.txt\", 'w', encoding = 'utf-8') as f:\n",
        "  for ex in dataset:\n",
        "    f.write(f\"–í–≤–æ–¥ {ex['input']}\\n–û—Ç–≤–µ—Ç: {ex['output']}\\n\\n\")\n",
        "\n",
        "train_dataset = create_dataset(\"train.txt\", tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./code_error_model\",\n",
        "    overwrite_output_dir = True,\n",
        "    num_train_epochs = 3,\n",
        "    per_device_train_batch_size = 2,\n",
        "    save_steps = 10_000,\n",
        "    save_total_limit = 2,\n",
        "    logging_steps = 500\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    data_collator = data_collator,\n",
        "    train_dataset = train_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "phXmhQdTUUyK",
        "outputId": "e8b46fe8-65bf-46fb-fdf1-1f305e99610e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4938' max='4938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4938/4938 09:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.148300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.057700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.051300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.045600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.042000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.041100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.038800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.038400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.036300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4938, training_loss=0.053830280435283255, metrics={'train_runtime': 555.4567, 'train_samples_per_second': 17.775, 'train_steps_per_second': 8.89, 'total_flos': 644934057984000.0, 'train_loss': 0.053830280435283255, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_model(prompt):\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "  # Move inputs to the same device as the model\n",
        "  inputs = {name: tensor.to(model.device) for name, tensor in inputs.items()}\n",
        "  outputs = model.generate(**inputs, max_length=150)\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
        "\n",
        "print(ask_model(\"–í–≤–æ–¥: for i in range(10) print(i)\\n–û—Ç–≤–µ—Ç:\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qktgnMPiVG3",
        "outputId": "107cd611-4aa8-4897-e2c0-58c6810202e8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–í–≤–æ–¥: for i in range(10) print(i)\n",
            "–û—Ç–≤–µ—Ç: –û—à–∏–±–∫–∞: –ø—Ä–æ–ø—É—â–µ–Ω —Å–∏–º–≤–æ–ª ':'. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥: for i in range(10): print(i)\n",
            "\n",
            "–í–≤–æ–¥ if x == 5\n",
            " print('ok)\n",
            "–û—Ç–≤–µ—Ç: –û—à–∏–±–∫–∞: –ø—Ä–æ–ø—É—â–µ–Ω —Å–∏–º–≤–æ–ª ':'. –ò—Å–ø—Ä–∞–≤–ª–µ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "prompt = input(\"–í–≤–æ–¥ –∫–æ–¥–∞: \")\n",
        "result = ask_model(prompt)\n",
        "print(\"\\n–û—Ç–≤–µ—Ç:\", result)\n"
      ],
      "metadata": {
        "id": "ocbdo49Wk2jm",
        "outputId": "3e18ed3d-4bf2-498b-e1f8-79c93ab15fef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–í–≤–æ–¥ –∫–æ–¥–∞: 5+5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "–û—Ç–≤–µ—Ç: 5+5\n",
            " print('ok)\n",
            "–û—Ç–≤–µ—Ç: –û—à–∏–±–∫–∞: –ø—Ä–æ–ø—É—â–µ–Ω —Å–∏–º–≤–æ–ª ':'. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥: if x == 5:\n",
            " print('ok)\n",
            "\n",
            "–í–≤–æ–¥ if x == 5\n",
            " print('ok)\n",
            "–û—Ç–≤–µ—Ç: –û—à–∏–±–∫–∞: –ø—Ä–æ–ø—É—â–µ–Ω —Å–∏–º–≤–æ–ª ':'. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name)\n",
        "\n",
        "print(\"Hi\", name)\n"
      ],
      "metadata": {
        "id": "1ynljE3EofsQ",
        "outputId": "49dcae08-6f55-4560-80d5-bdbdfe7548b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (ipython-input-12-736656388.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-12-736656388.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def greet(name)\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab-github-demo.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}